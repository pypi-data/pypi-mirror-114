tokenizer:
  vocab_size: 30000
  special_tokens: []
  additional_special_tokens: []
  model_max_length: null
  show_progress: true
tokenizer_trainer:
  save_directory: ???
model:
  model_path: null
  model_type: t5
  config_name: t5-base
  tokenizer_path: /Users/mozharovsky/Desktop/git-t5-tokenizer/tokenizer
  use_fast_tokenizer: true
  cache_dir: /Users/mozharovsky/Desktop/git-t5-tokenizer/model
  learning_rate: 5.0e-05
  weight_decay: 0.0
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-08
  adafactor: false
  scheduler_type: LINEAR
  warmup_steps: 0
  dtype: float32
  seed: 42
data:
  dataset_name: null
  dataset_config_name: null
  dataset_path: /Users/mozharovsky/Desktop/git-t5-tokenizer/data
  dataset_column: text
  model_path: ${model.model_path}
  tokenizer_path: ${model.tokenizer_path}
  use_fast_tokenizer: ${model.use_fast_tokenizer}
  cache_dir: ${model.cache_dir}
  overwrite_cache: false
  validation_size: 0.05
  max_sequence_length: 512
  train_batch_size: 1
  eval_batch_size: 1
  num_workers: 8
  mlm_probability: 0.15
  mean_noise_span_length: 3.0
  decoder_start_token_id: 0
  seed: ${model.seed}
trainer:
  output_dir: ???
  max_epochs: 3
  logging_steps: 1
  save_steps: 500
  eval_steps: 2000
  push_to_hub: false
  push_to_hub_model_id: null
  push_to_hub_organization: null
  push_to_hub_token: null
  checkpoint_dir: null
logger:
  name: t5_experiment_01
  save_dir: null
  offline: null
  run_id: null
  anonymous: null
  version: null
  project: t5_tpu
  prefix: null
