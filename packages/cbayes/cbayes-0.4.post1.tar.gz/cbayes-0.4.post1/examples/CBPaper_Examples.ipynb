{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistent Bayes: Examples from the Paper\n",
    "---\n",
    "\n",
    "Copyright 2018 Michael Pilosov\n",
    "\n",
    "Based on work done by ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "_tested with python 3.6 on 02/11/18_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematics and Plotting\n",
    "from HelperFuns import * # pyplot wrapper functions useful for visualizations, numpy, scipy, etc.\n",
    "# %matplotlib inline\n",
    "%matplotlib notebook\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams['figure.figsize'] = 10, 5\n",
    "from cbayes import sample, solve, distributions\n",
    "# Interactivity\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Summary\n",
    "\n",
    "---\n",
    "## Example 6.1\n",
    "\n",
    "We solve the following nonlinear system:\n",
    "\n",
    "$$\n",
    "\\lambda_1 \\,  x_1^2 + x_2^2 = 1  \\\\\n",
    "x_1^2 - \\lambda_2 \\, x_2^2 = 1\n",
    "$$\n",
    "\n",
    "Rearranging the second equation to get $x_1^2 = 1 + \\lambda_2 \\, x_2^2$, which we substitute into the first equation and perform some rearranging:\n",
    "\n",
    "$$\n",
    "\\lambda_1 \\, ( 1 + \\lambda_2 \\, x_2^2 ) + x_2^2 = 1 \\\\\n",
    "\\lambda_1 + \\lambda_1 \\lambda_2 \\, x_2^2 + x_2^2 = 1\\\\\n",
    "\\lambda_1 + (1 + \\lambda_1 \\lambda_2) \\, x_2^2 = 1 \\\\\n",
    "$$\n",
    "\n",
    "This then leads us to the following solution:\n",
    "$$\n",
    "x_1^2 = 1 + \\frac{\\lambda_2 - \\lambda_2 \\lambda_1}{1 + \\lambda_1 \\lambda_2} \\\\\n",
    "x_2^2 = \\frac{1 - \\lambda_1}{1 + \\lambda_1 \\lambda_2}\n",
    "$$\n",
    "\n",
    "Here, $\\Lambda = [0.79, 0.99] \\times [1 - 4.5\\sqrt{0.1}, \\,1 + 4.5\\sqrt{0.1}]$.  \n",
    "\n",
    "Our quantity of interest is simply $q(x) = x_2$\n",
    "\n",
    "We impose **Beta(2, 5)** and **Beta(1, 1)** over the support as our two priors that we investigate for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Example 6.2\n",
    "\n",
    "Here we have a piecewise-defined function $q: d\\to 1$ which is quite convoluted but defined for an abitrary input dimension, though we restrict ourselves to the case where $d = 2$, so $\\lambda = (\\lambda_1, \\lambda_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "q(\\lambda) = \n",
    "\\begin{cases} \n",
    "q_1(\\lambda) - 2 & \\text{ if } 3\\, \\lambda_1 + 2\\, \\lambda_2 \\geq 0 \\text{ and } -\\lambda_1 + 0.3\\, \\lambda_2 \\lt 0 \\\\ \n",
    "q_2(\\lambda) & \\text{ if } 3\\, \\lambda_1 + 2\\, \\lambda_2 \\geq 0 \\text{ and } -\\lambda_1 + 0.3\\, \\lambda_2 \\geq 0 \\\\\n",
    "2\\, q_1(\\lambda) + 4 & \\text{ if } (\\lambda_1 + 1)^2 + ( \\lambda_2 + 1)^2 \\lt 0.95^2 \\text{ and } d = 2 \\\\\n",
    "q_1(\\lambda) & \\text{ otherwise }\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\n",
    "q_1(\\lambda) = \\exp \\left (- \\sum_{i=1}^{d} \\lambda_i^2 \\right ) - \\lambda_1^3 - \\lambda_2^3, \\text{ and } \\\\ \n",
    "q_2(\\lambda) = 1 + q_1(\\lambda) + \\frac{1}{4d} \\sum_{i=1}^{d} \\lambda_i^2\n",
    "$$\n",
    "\n",
    "\n",
    "Here, $\\Lambda = [-1, 1]^2$ and we use **Beta(1,1)** over the support as our prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun1(lam):\n",
    "    if lam.shape[1] != 2:\n",
    "        raise(AttributeError('Your lambda must be two-dimensional'))\n",
    "    # our QoI here is just x_2. \n",
    "    numerator = 1.0 - lam[:,0]\n",
    "    denominator = 1 + np.product(lam, axis=1)\n",
    "    return np.sqrt(np.divide(numerator, denominator))\n",
    "\n",
    "def q1(lam):\n",
    "    L1 = lam[:,0] # local column-vectors.\n",
    "    L2 = lam[:,1]\n",
    "    ell2 = np.linalg.norm(lam, axis=1) # ell^2 norm (euclidean) for convenience later.\n",
    "    return np.exp(-ell2) - L1**3 - L2**3\n",
    "     \n",
    "def q2(lam):\n",
    "    d = lam.shape[1]\n",
    "    L1 = lam[:,0] # local column-vectors.\n",
    "    L2 = lam[:,1]\n",
    "    ell2 = np.linalg.norm(lam, axis=1) # ell^2 norm (euclidean) for convenience later.\n",
    "    return 1.0 + q1(lam) + 0.25*d*ell2\n",
    "    \n",
    "def fun2(lam):\n",
    "    n = lam.shape[0]\n",
    "    d = lam.shape[1] # get dimension. Should check for conformity to size, but we'll just assume it's right.\n",
    "    L1 = lam[:,0] # give first two columns names for convenience \n",
    "    L2 = lam[:,1] # later when we define our conditional statements.\n",
    "    \n",
    "    # now let's figure out how to partition our space up... \n",
    "    inds1 = np.where( (3*L1 + 2*L2 >= 0) & (-L1 + 0.3*L2 < 0) )[0] # this weird syntax is because of `np.where`\n",
    "    inds2 = np.where( (3*L1 + 2*L2 >= 0) & (-L1 + 0.3*L2 >= 0) )[0]\n",
    "    \n",
    "    if d == 2:\n",
    "        inds3 = np.where( ( (L1 + 1.0)**2 + (L2 + 1.0)**2 ) < 0.95**2 )[0]\n",
    "        inds4 = np.where( (3*L1 + 2*L2 < 0) & ( (L1 + 1.0)**2 + (L2 + 1.0)**2  > 0.95**2) )[0]\n",
    "    else:\n",
    "        inds3 = [] # if d != 2, this map \n",
    "        inds4 = np.where( (3*L1 + 2*L2 < 0) )[0]\n",
    "        \n",
    "    output = np.zeros(n)\n",
    "    output[inds1] = q1(lam[inds1,:]) - 2.0\n",
    "    output[inds2] = q2(lam[inds2,:])\n",
    "    output[inds3] = 2*q1(lam[inds3,:]) + 4.0\n",
    "    output[inds4] = q1(lam[inds4,:])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Sample from Prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PtO_fun_choice = 1\n",
    "dist = 'beta' # for example 6.1. Ex 6.2 uses uniform.\n",
    "\n",
    "input_dim = 2 # Specify input space dimension (n)\n",
    "num_samples = int(1E4) # number of input samples (N)\n",
    "s_set = sample.sample_set(size=(num_samples, input_dim))\n",
    "\n",
    "if PtO_fun_choice == 1:\n",
    "    PtO_fun = fun1\n",
    "    if dist == 'beta':\n",
    "        s_set.set_dist('beta', kwds={'a': 2, 'b': 5, 'loc': 0.79, 'scale': 0.20}, dim=0)\n",
    "        s_set.set_dist('beta', kwds={'a': 2, 'b': 5, 'loc': 1-4.5*np.sqrt(0.1), 'scale': 9*np.sqrt(0.1)}, dim=1)\n",
    "    elif dist == 'uni':\n",
    "        s_set.set_dist('beta', kwds={'a': 1, 'b': 1, 'loc': 0.79, 'scale': 0.20}, dim=0)\n",
    "        s_set.set_dist('beta', kwds={'a': 1, 'b': 1, 'loc': 1-4.5*np.sqrt(0.1), 'scale': 9*np.sqrt(0.1)}, dim=1)\n",
    "\n",
    "elif PtO_fun_choice == 2:\n",
    "    PtO_fun = fun2\n",
    "    s_set.set_dist('beta', kwds={'a': 1, 'b': 1, 'loc': -1, 'scale': 2}, dim=0)\n",
    "    s_set.set_dist('beta', kwds={'a': 1, 'b': 1, 'loc': -1, 'scale': 2}, dim=1)\n",
    "\n",
    "s_set.generate_samples()\n",
    "\n",
    "lam = s_set.samples # create a pointer for ease of reference later with plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Prior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfbc0a389ee424eb20c8dd9c0bc9a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='view_dim_1', max=1), IntSlider(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.interactive(pltdata, data = fixed(lam), inds = fixed(None), \n",
    "                    N = widgets.IntSlider(value=500, min = 100, max=5000, step=100, continuous_update=False), \n",
    "                    eta_r = fixed(None), space=fixed(0.05), svd=widgets.Checkbox(value=False), color=widgets.Text(value=\"orange\", continuous_update=False),\n",
    "                    view_dim_1 = widgets.IntSlider(value=0, min=0, max=input_dim-1, step=1, continuous_update=False), \n",
    "                    view_dim_2 = widgets.IntSlider(value=input_dim-1, min=0, max=input_dim-1, step=1, continuous_update=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Compute Data Space $O(\\Lambda) = \\mathcal{D}$ \n",
    "\n",
    "Format: `(n_dims, n_samples)`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_set = sample.map_samples_and_create_problem(s_set, PtO_fun)\n",
    "D = p_set.output.samples\n",
    "print('dimensions :  lambda = '+str(lam.shape)+'   D = '+str(D.shape) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Push-Forward of the Prior $P_{O(\\Lambda)}$\n",
    "_ ... i.e. Characterize the Data Space_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PtO_fun_choice == 1:\n",
    "    p_set.compute_pushforward_dist(method='sklearn', kwds={'bandwidth':0.05})\n",
    "else:\n",
    "    p_set.compute_pushforward_dist(method='sklearn', kwds={'bandwidth':0.25})\n",
    "pf_dist = p_set.pushforward_dist # create handle for later reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Observed Probability Measure $P_\\mathcal{D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PtO_fun_choice == 1:\n",
    "    p_set.set_observed_dist('normal', {'loc':0.3, 'scale':0.025}, dim=0) # default is normal based on the data space # for function choice = 1\n",
    "\n",
    "elif PtO_fun_choice == 2:\n",
    "    p_set.set_observed_dist('normal', {'loc':-2.0, 'scale':0.25**2}, dim=0) # default is normal based on the data space # for function choice = 1\n",
    "\n",
    "\n",
    "output_dim = p_set.output.dim\n",
    "if PtO_fun_choice == 1:\n",
    "    xx = np.linspace(-0.3,1,100).reshape(-1,1)\n",
    "else:\n",
    "    xx = np.linspace(-6,10,100).reshape(-1,1)\n",
    "\n",
    "obs_dist = p_set.observed_dist # this is define a pointer for ease of reference.\n",
    "zz = pf_dist.pdf(xx)\n",
    "plt.plot(xx, zz, c='blue',label='pf_prior')\n",
    "\n",
    "yy = obs_dist.pdf(xx)\n",
    "plt.plot(xx, yy,c='orange',label='observed')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "At this point we have performed the computations we need to. We have evaluated the input points through our map and performed a KDE on them. It would be useful at this point to save this object and/or its evaluation at every point in the data space for later re-use. Doing so here would be an appropriate place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Accept/Reject Sampling of Posterior\n",
    "\n",
    "Since we have already used the samples in our prior to compute the pushforward density, we can re-use these with an accept/reject algorithm to get a set of samples generated from the posterior according to the solution of the stochastic inverse problem as outlined in the Consistent Bayes formulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_set.set_ratio()\n",
    "eta_r = p_set.ratio\n",
    "solve.problem(p_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_inds = p_set.accept_inds\n",
    "lam_accept = p_set.input.samples[accept_inds,:]\n",
    "num_accept = len(accept_inds)\n",
    "print('Number accepted: %d = %2.2f%%'%(num_accept, 100*np.float(num_accept)/num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Posterior Density\n",
    "### (Visualize Accept/Reject Samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "widgets.interactive(pltdata, data = fixed(lam), inds = fixed(accept_inds), \n",
    "        N = widgets.IntSlider(value=num_accept/2, min = 2, max=num_accept, step=1, continuous_update=False), \n",
    "        eta_r = fixed(None), space=fixed(0.05), svd=widgets.Checkbox(value=False), color=widgets.Text(value=\"orange\", continuous_update=False),\n",
    "        view_dim_1 = widgets.IntSlider(value=0, min=0, max=input_dim-1, step=1, continuous_update=False), \n",
    "        view_dim_2 = widgets.IntSlider(value=input_dim-1, min=0, max=input_dim-1, step=1, continuous_update=False))\n",
    "\n",
    "# You will visualize the accepted samples in a subset of size N of the input samples. \n",
    "# This is mostly for faster plotting, but also so you can see the progression of accepted sampling in the algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Now what? \n",
    "\n",
    "Well, we can...\n",
    "\n",
    "## _Visualize the Quality of our SIP Solution by Comparing it to the Observed_\n",
    "_We compare the push-forward of the posterior using accepted samples against the observed density_  \n",
    "_(SIP = Stochastic Inverse Problem)_\n",
    "### Observed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "widgets.interactive(pltdata, data = fixed(obs_dist), inds = fixed(None), \n",
    "        N = widgets.IntSlider(value=500, min = 100, max=5000, step=100, continuous_update=False), \n",
    "        eta_r = fixed(None), space=fixed(0.05), svd=fixed(False), color=widgets.Text(value=\"wine\", continuous_update=False),\n",
    "        view_dim_1 = widgets.IntSlider(value=0, min=0, max=output_dim-1, step=1, continuous_update=False), \n",
    "        view_dim_2 = widgets.IntSlider(value=output_dim-1, min=0, max=output_dim-1, step=1, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushforward of Posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interactive(pltdata, data = fixed(D), inds = fixed(accept_inds), \n",
    "        N = widgets.IntSlider(value=num_accept/2, min = 2, max=num_accept-1, step=1, continuous_update=False), \n",
    "        eta_r = fixed(None), space=fixed(0.05), svd=fixed(False), color=widgets.Text(value=\"eggplant\", continuous_update=False),\n",
    "        view_dim_1 = widgets.IntSlider(value=0, min=0, max=output_dim-1, step=1, continuous_update=False), \n",
    "        view_dim_2 = widgets.IntSlider(value=output_dim-1, min=0, max=output_dim-1, step=1, continuous_update=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify our parametric test statistics.\n",
    "Let's see if the pushforward of the posterior results in a sample mean and standard deviation that are close to the observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.mean(D[accept_inds,:]), np.std(D[accept_inds,:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p_set.observed_dist.mean(), p_set.observed_dist.std()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look pretty good! Now go back to the [Sampling Section](#Sample-from-Prior) and change the distribution on the prior or choose another example problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
