{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Statistical and Consistent Bayesian Inversion\n",
    "\n",
    "We define a problem where the observed density corresponds to a likelihood function from classical Bayesian inversion\n",
    "\n",
    "Copyright 2018 Michael Pilosov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sstats\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "plt.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbayes.sample as samp\n",
    "import cbayes.distributions as dist\n",
    "import cbayes.solve as solve\n",
    "import scipy.integrate as integrate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as wid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistent Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparesandbox(N = int(5E3), M = 5, pr_mean = 0, pr_sd = 0.5, ob_mean = 0.5, ob_sd = 0.5, \n",
    "                   bw = 0, p=1, cb=False, cbpf=True, sb=False, sbpf=True, pfpr=False):\n",
    "    np.random.seed()\n",
    "    s_set = samp.sample_set(size=(N, 1))\n",
    "    s_set.set_dist('norm', kwds={'loc':pr_mean, 'scale':pr_sd}, dim=0)\n",
    "#     ob_sd = np.sqrt(50./M)\n",
    "\n",
    "    obs_data = ob_mean + ob_sd*np.random.randn(int(M))\n",
    "    def QoI_fun(lam):\n",
    "        try:\n",
    "            q = np.power(lam.reshape(-1,1), np.float(p))\n",
    "        except AttributeError:\n",
    "            q = np.power(lam, np.float(p))\n",
    "        if M > 1:\n",
    "            residuals = q  - obs_data\n",
    "            return (1./M)*np.sum( (residuals/ob_sd)**2, axis=1 ).reshape(-1,1)\n",
    "        else:\n",
    "            return q\n",
    "    if p > 1 and bw==0:\n",
    "        bw = 0.05\n",
    "        \n",
    "    s_set.generate_samples()\n",
    "    p_set = samp.map_samples_and_create_problem(s_set, QoI_fun)\n",
    "    if M == 1:\n",
    "        p_set.set_observed_dist(dist='norm', dim=0, kwds={'loc':ob_mean, 'scale': ob_sd})\n",
    "    else:\n",
    "        p_set.set_observed_dist(dist='gamma', dim=0, kwds={'a':M/2, 'scale':2/M})\n",
    "        \n",
    "    if bw > 0:\n",
    "        p_set.compute_pushforward_dist(method='sk', kwds={'bandwidth': bw})\n",
    "    else:\n",
    "        p_set.compute_pushforward_dist(method='sc') # use scipy instead if you dont care about bw (faster)\n",
    "        \n",
    "    # CREATE SHORT-VERSION FUNCTION HANDLES (for convenience)\n",
    "    pf = p_set.pushforward_dist\n",
    "    pr = p_set.prior_dist\n",
    "    ob = p_set.observed_dist\n",
    "    \n",
    "    # Solve CBayes \n",
    "    p_set.set_ratio()\n",
    "    indC = solve.perform_accept_reject(p_set.output.samples, p_set.ratio, seed=21)\n",
    "    \n",
    "    # Solve SBayes\n",
    "    def like(lam): # Taken from Smith, pg 156\n",
    "        if type(lam) is float:\n",
    "            lam = np.array(lam)\n",
    "        q = np.power(lam.reshape(-1, 1), np.float(p))\n",
    "        residuals = q  - obs_data\n",
    "        xx = (1./2)*np.sum( (residuals/ob_sd)**2, axis=1 ).reshape(-1,1)\n",
    "        return np.exp(-xx)/(2*np.pi*ob_sd**2)**np.float(M/2)\n",
    "    \n",
    "    def S_post(x): \n",
    "        return p_set.input.dist.pdf(x)*like(x).flatten()\n",
    "    \n",
    "    likelihood = like(p_set.input.samples)\n",
    "    evidence=integrate.quad(S_post,-3,3)\n",
    "    print('Evidence: %2.4f'%evidence[0])\n",
    "    indS = solve.perform_accept_reject(p_set.input.samples, likelihood, seed=225)\n",
    "    print(\"ACCEPTED:\", \"SB:\", len(indS), \"| CB:\", len(indC), \" OF\", N)\n",
    "    \n",
    "    \n",
    "#     def C_post(x): # kind of works, kind of doesn't (if assumptions are violated)\n",
    "#         tol = 1E-4\n",
    "#         pfpr = p_set.pushforward_dist.pdf(QoI_fun(x))\n",
    "#         pfpr[pfpr < tol] = 1.0\n",
    "#         prr = p_set.input.dist.pdf(x)\n",
    "#         obb = p_set.observed_dist.pdf(QoI_fun(x))\n",
    "#         output = prr*obb/pfpr\n",
    "\n",
    "#         output[pfpr < tol] = pfpr[pfpr < tol]\n",
    "#         return output\n",
    "\n",
    "    if len(indC) < 10:\n",
    "        print(Warning(\"Be aware, too few accepted samples from Consistent Bayes\"))\n",
    "    if len(indS) < 10:\n",
    "        print(Warning(\"Be aware, too few accepted samples from Statistical Bayes\"))\n",
    "    \n",
    "    # SMOOTH (PUSH-FORWARDS OF) POSTERIORS FOR PLOTTING\n",
    "    if len(indC)>1:\n",
    "        cb_ps_den = dist.gkde(p_set.input.samples[indC])\n",
    "        cb_pf_den = dist.gkde(p_set.output.samples[indC])\n",
    "    else:\n",
    "        print(Warning(\"Only one accepted sample for Consistent Bayes.\"))\n",
    "       \n",
    "    if len(indS)>1:\n",
    "        sb_ps_den = dist.gkde(p_set.input.samples[indS])\n",
    "        sb_pf_den = dist.gkde(p_set.output.samples[indS])\n",
    "    else:\n",
    "        print(Warning(\"Only one accepted sample for Statistical Bayes.\"))\n",
    "    \n",
    "    \n",
    "    ## PLOTTING CODE\n",
    "    x = np.linspace(-3,3,1000)\n",
    "    LL = like(x)\n",
    "    plt.plot(x, pr.pdf(x), c = 'orange', ls='--', lw=3, label='Prior')\n",
    "    plt.plot(x, LL,  c='k', ls='--', lw=3, label='Statistical Likelihood Function')\n",
    "    plt.scatter(np.power(ob_mean, 1./p), [0.01], facecolor='k', s=200, label='true param')\n",
    "    plt.scatter(obs_data, 0*obs_data+0.01, s=50, label='data')\n",
    "    \n",
    "    if pfpr:\n",
    "        plt.plot(x,pf.pdf(x), label='Push-forward of Prior', c='k',lw=3)\n",
    "\n",
    "    \n",
    "    if cb and len(indC)>1:\n",
    "        plt.plot(x, cb_ps_den.pdf(x),  c='b', ls='-', lw=1, label='Consistent Posterior')\n",
    "#         plt.plot(x, C_post(x),  c='b', ls='--', label='Analytical Consistent Posterior ')\n",
    "    if cbpf and len(indC)>1:\n",
    "        plt.plot(x, ob.pdf(x), label='Observed', c='r')\n",
    "        plt.plot(x, cb_pf_den.pdf(x),  c='b', ls=':', lw=3, label='Consistent Posterior Push-forward')\n",
    "\n",
    "    if sb and len(indS)>1:\n",
    "        plt.plot(x, sb_ps_den.pdf(x),  c='g', ls='-', lw=1, label='Statistical Posterior')\n",
    "#         plt.plot(x, S_post(x)/evidence[0],  c='g', ls='--', lw=2, label='Analytical Statistical Posterior')\n",
    "    if sbpf and len(indS)>1:\n",
    "        plt.plot(x, sb_pf_den.pdf(x),  c='g', ls=':', lw=3, label='Statistical Posterior Push-forward')\n",
    "\n",
    "    \n",
    "    if M == 1:\n",
    "        plt.ylim([0,5])\n",
    "    else:\n",
    "        plt.ylim([0,5])\n",
    "    plt.xlim([-2.5,2.5])\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('Map with p=%d - Prior Mean at %.2f, M = %d'%(p, pr_mean, M))\n",
    "#     plt.savefig('comparison.png')\n",
    "    plt.show()\n",
    "#     return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = wid.IntSlider(value=int(5E3), min=100, max=int(1E4), step=100, continuous_update=False)\n",
    "M = wid.IntSlider(value=1, min=1, max=50, step=1, continuous_update=False)\n",
    "ob_sd = wid.FloatSlider(value=0.25,  min=0.01, max=1, step=0.01, continuous_update=False)\n",
    "ob_mean = wid.FloatSlider(value=1,  min=-0.5, max=1.5, step=0.25, continuous_update=False)\n",
    "pr_mean = wid.FloatSlider(value=0, min=-1, max=1, step=0.05, continuous_update=False)\n",
    "pr_sd = wid.FloatSlider(value=0.5,  min=0.25, max=3, step=0.05, continuous_update=False)\n",
    "bw = wid.FloatSlider(value=0,  min=0, max=0.5, step=0.01, continuous_update=False)\n",
    "p = wid.IntSlider(value=1, min=1, max=5, continuous_update=False)\n",
    "cb = wid.Checkbox(value=True)\n",
    "cbpf = wid.Checkbox(value=False)\n",
    "sb = wid.Checkbox(value=True)\n",
    "sbpf = wid.Checkbox(value=False)\n",
    "pfpr = wid.Checkbox(value=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133e89e2e8fb4c70bba11a001c04bc9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5000, continuous_update=False, description='N', max=10000, min=100, stepâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.comparesandbox>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wid.interact_manual(comparesandbox, N=N, M=M, \n",
    "                    ob_sd=ob_sd, ob_mean=ob_mean, \n",
    "                    pr_mean=pr_mean, pr_sd=pr_sd, bw=bw, \n",
    "                    p=p, cb=cb, cbpf=cbpf, sb=sb, sbpf=sbpf, pfpr=pfpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Bayes will look like the prior if the data is weak\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.value = 1\n",
    "p.value = 1\n",
    "pr_sd.value = 0.25\n",
    "ob_sd.value = 2\n",
    "pr_mean.value = 0\n",
    "ob_mean.value = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or under a nonlinear map\n",
    "We need to increase sample size to approximate the distribution well enough.\n",
    " We suggest increasing `N=10000` but even with just a few accepted samples, we recreate the observed density (which is still the same as the likelihood since `M=1` ) much more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N.value = 6500\n",
    "M.value = 1\n",
    "p.value = 5\n",
    "pr_sd.value = 0.25\n",
    "ob_sd.value = 0.1\n",
    "pr_mean.value = 0\n",
    "ob_mean.value = 0.25\n",
    "bw.value = 0.05\n",
    "pfpr.value = True\n",
    "cb.value = False\n",
    "sb.value = True\n",
    "sbpf.value = False\n",
    "cbpf.value = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With more data, the posteriors are similar (provided the signal-to-noise ratio is reasonable)\n",
    "(Despite solving a different problem, the Consistent Bayes approach does appear to solve the parameter identification problem as well). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N.value = 6500\n",
    "M.value = 5\n",
    "p.value = 5\n",
    "pr_sd.value = 0.25\n",
    "ob_sd.value = 0.15\n",
    "pr_mean.value = 0.75\n",
    "ob_mean.value = 1.0\n",
    "bw.value = 0.05\n",
    "pfpr.value = False\n",
    "cb.value = True\n",
    "sb.value = True\n",
    "sbpf.value = False\n",
    "cbpf.value = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can separate the truth from the data and get very strange posteriors, even under the identity map.\n",
    "Do note that this leads to few accepted samples.\n",
    "It violates an assumption of Consistent Bayes, so the solution will make no sense. It will do its best to capture samples that are under the observed density, which occurs rarely owing to the strong bias of the prior. \n",
    "We suggest moving `ob_mean` to the left and seeing how the posteriors change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.value = 1\n",
    "N.value = 5000\n",
    "p.value = 1\n",
    "pr_sd.value = 0.25\n",
    "ob_sd.value = 0.25\n",
    "pr_mean.value = 0\n",
    "ob_mean.value = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As more data comes in, Statistical Bayes starts to move towards data\n",
    "Go ahead and bump `M` up even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.value = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The methods will be the same under a uniform prior.\n",
    "(which we simulate by choosing a large prior standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_sd.value = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even with less data... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.value = 1\n",
    "ob_sd.value = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Really degenerate Case - violating assumptions\n",
    "Confident prior beliefs and a lot of poor quality data. More data does fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N.value = 5E3\n",
    "M.value = 10\n",
    "ob_mean.value = 1\n",
    "pr_mean.value = -0.5\n",
    "pr_sd.value = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confident prior beliefs and a paucity of confident data.\n",
    "Very few accepted samples for cbayes, but at least it's not just basically the prior...\n",
    "Note that we violate a consistent Bayesian assumption (predictability) when we do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.value = 1\n",
    "ob_mean.value = 2\n",
    "pr_mean.value = 0\n",
    "pr_sd.value = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
