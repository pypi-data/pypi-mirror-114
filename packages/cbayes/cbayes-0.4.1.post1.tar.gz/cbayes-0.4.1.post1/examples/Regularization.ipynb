{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import scipy.stats as sstats \n",
    "\n",
    "import ipywidgets\n",
    "from  ipywidgets import interact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Typical Linear Problem\n",
    "\n",
    "Consider the linear problem\n",
    "\n",
    "$$\n",
    "    q = Ax, \\ x\\in\\mathbb{R}^n, \\ q\\in \\mathbb{R}^p, \\ A\\in\\mathbb{R}^{p\\times n}\n",
    "$$\n",
    "\n",
    "where we assume that $p\\leq n$ and $A$ is rank $p$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Bayesian connection to Tikhonov regularization\n",
    "\n",
    "Assuming we observe datum $\\tilde{q}$ and that we are using a Gaussian prior ($N(\\bar{x},C_x)$) and Gaussian noise model ($N(0,C_q)$), the statistical Bayesian posterior is given by\n",
    "\n",
    "$$\n",
    "    \\pi^{\\text{post}} \\propto \\exp\\left(-\\frac{1}{2}\\left( \n",
    "    \\underbrace{\\left|\\left|C_q^{-1/2}(q-\\tilde{q})\\right|\\right|_2^2}_{\\text{Data mismatch}} + \n",
    "    \\underbrace{\\left|\\left|C_x^{-1/2}(x-\\bar{x})\\right|\\right|_2^2}_{\\text{Tikhonov regularization}}\n",
    "    \\right)\\right)\n",
    "$$\n",
    "\n",
    "where we have made explicit the connection of the MAP (maximum a posteriori) point of the posterior density with the Tikhnoov regularized solution to a deterministic optimization problem.\n",
    "\n",
    "See https://en.wikipedia.org/wiki/Tikhonov_regularization for more information.\n",
    "\n",
    "## Take-aways\n",
    "\n",
    "\n",
    "* The model defines the data mismatch and the prior defines the regularization. \n",
    "\n",
    "\n",
    "* The regularization impacts ***all directions*** of the posterior since we effectively balance the data mismatch with our prior beliefs. This implies that the \"solution\" defined by a MAP point is not necessarily a point that produces the observed datum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "Consider the linear problem where\n",
    "$$\n",
    "    A = [2 \\ -1],\\ \\bar{x}=\\left[\\begin{array}[c]  00.2 \\\\ 0.2 \\end{array}\\right],   \\\\\n",
    "    \\ C_x = \\text{diag}(0.5, 0.25),  \\\\\n",
    "    \\ \\tilde{q} = [0.1], \\ C_q = [0.25].\n",
    "$$\n",
    "\n",
    "## Things to play with\n",
    "\n",
    "* Try changing the `x_prior` in the code to something other than $[0.2 \\ 0.2]^\\top$ to make the prior guess either better or worse. What happens?\n",
    "\n",
    "* Try playing with the `C_x` covariance to give the prior guess either more confidence (reduce the components) or less confidence (increase the components). What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(n=101, data_cov_const=0.25, prior_x1=0.2, prior_x2=0.2, sigma_x1=0.5, sigma_x2=0.5):\n",
    "    # Discretize a portion of the input space R^2\n",
    "    # copied troy's code into here. \n",
    "    # Setup example and prior guess, prior prediction, and actual datum\n",
    "    a = 2\n",
    "    b = -1\n",
    "    \n",
    "    A = np.array([[a, b]]) #map\n",
    "    x_prior = np.array([prior_x1, prior_x2]).reshape(-1,1) #prior guess of mean\n",
    "    q_obs = np.array([0.1]) #actual datum # leave fixed.\n",
    "    q_prior = np.dot(A,x_prior) #predicted datum using prior\n",
    "    print('Prior Mean (x1,x2) =', *x_prior, 'maps to q =', *q_prior[0])    \n",
    "    \n",
    "    def data_misfit(x):\n",
    "        C_q_inv = np.linalg.inv(C_q)\n",
    "        q = np.dot(A,x)\n",
    "        WSSE = np.vdot(np.dot(C_q_inv,q-q_obs),q-q_obs) #weighted sum-squared error\n",
    "        res = q-q_obs\n",
    "        WSSE = res@C_q_inv@res\n",
    "        return WSSE\n",
    "    \n",
    "    def Tikhonov_reg(x):\n",
    "        C_x_inv = np.linalg.inv(C_x)\n",
    "        WSSE = np.vdot(np.dot(C_x_inv,x-x_prior),x-x_prior) #weighted sum-squared error\n",
    "        return WSSE\n",
    "\n",
    "    def unregularize(x):\n",
    "        C_A_inv = np.linalg.inv(C_A)\n",
    "        q = np.dot(A,x)\n",
    "        WSSE = np.vdot(np.dot(C_A_inv,q-q_prior),q-q_prior) #weighted sum-squared error\n",
    "        return WSSE\n",
    "\n",
    "    # Setup all the covariances\n",
    "    prior_cov = [sigma_x1, sigma_x2]\n",
    "    C_x = np.diag(prior_cov) #prior covariance\n",
    "    C_q = np.diag([data_cov_const]) #data covariance\n",
    "    C_A = np.dot(np.dot(A,C_x),A.transpose()) #the \"covariance of the map\"\n",
    "    \n",
    "    x1 = np.linspace(-0.5, 0.5,n)\n",
    "    x2 = x1\n",
    "    x1,x2 = np.meshgrid(x1,x2)\n",
    "    # Compute all the WSSE terms\n",
    "\n",
    "    WSSE = np.zeros((n,n))\n",
    "    TSSE = np.zeros((n,n))\n",
    "    USSE = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            WSSE[j,i] = data_misfit(np.array([[x1[j,i],x2[j,i]]]).transpose())\n",
    "            TSSE[j,i] = Tikhonov_reg(np.array([[x1[j,i],x2[j,i]]]).transpose())\n",
    "            USSE[j,i] = unregularize(np.array([[x1[j,i],x2[j,i]]]).transpose())\n",
    "\n",
    "    x_reg_ind = np.argmin(WSSE+TSSE)\n",
    "    x_unreg_ind = np.argmin(WSSE+TSSE-USSE)\n",
    "\n",
    "    \n",
    "    print('Absolute error in prediction through Tikonov: ', \n",
    "      np.abs(0.1 - np.dot(A,[x1.flatten()[x_reg_ind],x2.flatten()[x_reg_ind]])[0]))\n",
    "\n",
    "    print('Absolute error in prediction through CB: ', \n",
    "      np.abs(0.1 - np.dot(A,[x1.flatten()[x_unreg_ind],x2.flatten()[x_unreg_ind]])[0]))\n",
    "\n",
    "    \n",
    "    f, axarr = plt.subplots(2, 3, figsize=[20,20])\n",
    "    i, j = 0,0\n",
    "    ax = axarr[i,j]\n",
    "    ax.set_xlabel('$x_1$')\n",
    "    ax.set_ylabel('$x_2$')\n",
    "    ax.set_title('Prior')\n",
    "    ax.set_aspect('equal')\n",
    "    Z = sstats.multivariate_normal.pdf(np.concatenate([x1.reshape(-1,1), x2.reshape(-1,1)], axis=1), mean=x_prior.flatten(), cov=np.diag(prior_cov))\n",
    "    ax.pcolormesh(x1, x2, Z.reshape(n,n), cmap=cm.hot, linewidth=0, antialiased=False)\n",
    "    ax.scatter([x_prior[0]], [x_prior[1]], s=250,facecolor='red')\n",
    "    Mv = ['WSSE', 'TSSE']\n",
    "    for M in [WSSE, TSSE]:\n",
    "        ax = axarr[i,j+1]\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_xlabel('$x_1$')\n",
    "        ax.set_ylabel('$x_2$')\n",
    "        ax.set_title(Mv[j])          \n",
    "        ax.pcolormesh(x1, x2, M, cmap=cm.hot, linewidth=0, antialiased=False)\n",
    "        if Mv[j] == 'WSSE':\n",
    "            plt.plot(x1,x1, '-', color='blue', zorder=10)\n",
    "        j +=1\n",
    "        \n",
    "    i, j = 1, 0\n",
    "    Mv = ['WSSE + TSSE - USSE', 'TSSE - USSE', 'WSSE + TSSE', ]\n",
    "    for M in [WSSE + TSSE - USSE, TSSE-USSE, WSSE + TSSE]:\n",
    "        \n",
    "        ax = axarr[i,j]\n",
    "        ax.set_aspect('equal')\n",
    "        ax.pcolormesh(x1, x2, M, cmap=cm.hot, linewidth=0, antialiased=False)\n",
    "        if j == 0:\n",
    "            ax.scatter([x1.flatten()[x_unreg_ind]], [x2.flatten()[x_unreg_ind]], s=250, facecolor='blue')\n",
    "            ax.scatter([x_prior[0]], [x_prior[1]], s=250,facecolor='red')\n",
    "        if j == 2:\n",
    "            ax.scatter([x1.flatten()[x_reg_ind]], [x2.flatten()[x_reg_ind]], s=250, facecolor='blue')\n",
    "            ax.scatter([x_prior[0]], [x_prior[1]], s=250,facecolor='red')\n",
    "        ax.set_xlabel('$x_1$')\n",
    "        ax.set_ylabel('$x_2$')\n",
    "        ax.set_title(Mv[j])\n",
    "        \n",
    "        j +=1\n",
    "        \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79c7a6a68364ab2b8e419e9e6c14c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.05, continuous_update=False, description='data_cov_const', max=2.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.solve>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(solve, n = ipywidgets.fixed(101),\n",
    "                   data_cov_const=ipywidgets.FloatSlider(value=0.05, min=0.001, max=2, step=0.001, continuous_update=False),\n",
    "                   sigma_x1=ipywidgets.FloatSlider(value=0.5, min=0.025, max=2.5, step=0.025, continuous_update=False), \n",
    "                   sigma_x2=ipywidgets.FloatSlider(value=0.25, min=0.025, max=2.5, step=0.025,  continuous_update=False), \n",
    "                   prior_x1=ipywidgets.FloatSlider(value=0.2, min=-0.5, max=0.5, continuous_update=False), \n",
    "                   prior_x2=ipywidgets.FloatSlider(value=0.2, min=-0.5, max=0.5, continuous_update=False)\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
